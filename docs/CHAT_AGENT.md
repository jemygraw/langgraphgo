# ChatAgent - Multi-Turn Conversation Support

`ChatAgent` provides a high-level API for building conversational agents with automatic session management and conversation history.

## Features

- **Automatic Session Management**: Each ChatAgent instance has a unique session ID (thread ID)
- **Conversation History**: Messages are automatically accumulated and passed to the agent
- **Simple API**: Easy-to-use `Chat()` method for multi-turn conversations
- **Memory**: The agent maintains full conversation context across multiple turns
- **Dynamic Tools**: Add, remove, or update tools at runtime during conversations
- **Async Streaming**: Stream responses in real-time with `AsyncChat()` and `AsyncChatWithChunks()`

## Basic Usage

```go
import (
    "context"
    "github.com/smallnest/langgraphgo/prebuilt"
    "github.com/tmc/langchaingo/llms/openai"
)

// Create an LLM model
model, err := openai.New(openai.WithModel("gpt-4"))
if err != nil {
    log.Fatal(err)
}

// Create a ChatAgent with optional tools
agent, err := prebuilt.NewChatAgent(model, tools)
if err != nil {
    log.Fatal(err)
}

ctx := context.Background()

// Have a multi-turn conversation
response1, err := agent.Chat(ctx, "Hello! My name is Alice.")
response2, err := agent.Chat(ctx, "What's my name?")
// The agent will remember the name from the previous message

// Get the session ID
sessionID := agent.ThreadID()
```

## API

### NewChatAgent

```go
func NewChatAgent(model llms.Model, inputTools []tools.Tool, opts ...CreateAgentOption) (*ChatAgent, error)
```

Creates a new ChatAgent with the specified model and tools.

**Parameters:**
- `model`: The LLM model to use (e.g., OpenAI GPT-4)
- `inputTools`: Optional slice of tools the agent can use
- `opts`: Optional configuration (system message, state modifier, etc.)

**Returns:**
- `*ChatAgent`: A new ChatAgent instance
- `error`: Any error that occurred during creation

### Chat

```go
func (c *ChatAgent) Chat(ctx context.Context, message string) (string, error)
```

Sends a message to the agent and returns the response. The conversation history is automatically maintained.

**Parameters:**
- `ctx`: Context for the operation
- `message`: The user's message

**Returns:**
- `string`: The agent's response
- `error`: Any error that occurred

### ThreadID

```go
func (c *ChatAgent) ThreadID() string
```

Returns the unique session ID for this conversation.

### PrintStream

```go
func (c *ChatAgent) PrintStream(ctx context.Context, message string, w io.Writer) error
```

Sends a message and prints the response to the provided writer.

### AsyncChat

```go
func (c *ChatAgent) AsyncChat(ctx context.Context, message string) (<-chan string, error)
```

Sends a message to the agent and returns a channel for **TRUE streaming** of the response. This method uses the LLM's native streaming API (via `llms.WithStreamingFunc`) to send chunks as they're generated by the model in real-time, not after the full response is ready.

**Key Features:**
- **Real-time Streaming**: Chunks arrive as the LLM generates them
- **Native LLM Support**: Uses the underlying model's streaming capabilities
- **Low Latency**: First tokens appear immediately
- **Efficient**: No buffering of complete response before sending

**Parameters:**
- `ctx`: Context for the operation (supports cancellation)
- `message`: The user's message

**Returns:**
- `<-chan string`: Read-only channel that sends response chunks in real-time
- `error`: Any error that occurred during initialization

**Example:**
```go
respChan, err := agent.AsyncChat(ctx, "Explain quantum computing")
if err != nil {
    log.Fatal(err)
}

// Chunks arrive as the LLM generates them
for chunk := range respChan {
    fmt.Print(chunk)  // Print each chunk immediately
}
```

**Note:** The channel receives chunks as they're generated by the LLM. Chunk size depends on the model's streaming implementation (usually word or sub-word tokens).

### AsyncChatWithChunks

```go
func (c *ChatAgent) AsyncChatWithChunks(ctx context.Context, message string) (<-chan string, error)
```

Sends a message to the agent and returns a channel for streaming the response word by word. Unlike `AsyncChat`, this streams in word-sized chunks for better readability while still providing a streaming effect.

**Parameters:**
- `ctx`: Context for the operation (supports cancellation)
- `message`: The user's message

**Returns:**
- `<-chan string`: Read-only channel that sends words and spaces
- `error`: Any error that occurred during initialization

**Example:**
```go
respChan, err := agent.AsyncChatWithChunks(ctx, "Explain AI")
if err != nil {
    log.Fatal(err)
}

var fullResponse string
for word := range respChan {
    fmt.Print(word)
    fullResponse += word
}
```

## Dynamic Tool Management

ChatAgent supports adding and removing tools dynamically during a conversation. This enables powerful use cases like context-aware capabilities, resource management, and progressive enhancement.

### SetTools

```go
func (c *ChatAgent) SetTools(newTools []tools.Tool)
```

Replaces all dynamic tools with the provided tools. This does not affect base tools provided during agent creation.

**Example:**
```go
agent.SetTools([]tools.Tool{weatherTool, calculatorTool})
```

### AddTool

```go
func (c *ChatAgent) AddTool(tool tools.Tool)
```

Adds a new tool to the dynamic tools list. If a tool with the same name already exists, it will be replaced.

**Example:**
```go
weatherTool := &WeatherTool{}
agent.AddTool(weatherTool)
```

### RemoveTool

```go
func (c *ChatAgent) RemoveTool(toolName string) bool
```

Removes a tool by name from the dynamic tools list. Returns `true` if the tool was found and removed, `false` otherwise.

**Example:**
```go
removed := agent.RemoveTool("calculator")
if removed {
    fmt.Println("Calculator tool removed")
}
```

### GetTools

```go
func (c *ChatAgent) GetTools() []tools.Tool
```

Returns a copy of the current dynamic tools list. This does not include base tools provided during agent creation.

**Example:**
```go
tools := agent.GetTools()
fmt.Printf("Agent has %d dynamic tools\n", len(tools))
```

### ClearTools

```go
func (c *ChatAgent) ClearTools()
```

Removes all dynamic tools.

**Example:**
```go
agent.ClearTools()
```

## Dynamic Tools Use Cases

### 1. Context-Aware Capabilities

Add tools based on conversation context:

```go
// Add calculator when user mentions math
if strings.Contains(message, "calculate") {
    agent.AddTool(calculatorTool)
}

response, _ := agent.Chat(ctx, message)
```

### 2. Progressive Enhancement

Start simple and add advanced tools as needed:

```go
// Basic agent
agent, _ := prebuilt.NewChatAgent(model, basicTools)

// Add advanced tools when user is ready
if userLevel == "advanced" {
    agent.AddTool(advancedAnalyticsTool)
    agent.AddTool(dataVisualizationTool)
}
```

### 3. Resource Management

Remove expensive tools when not needed:

```go
// Remove API-based tools after quota exceeded
if quotaExceeded {
    agent.RemoveTool("expensive_api")
}
```

### 4. Access Control

Grant or revoke tool access based on permissions:

```go
// Grant file access only after authentication
if user.IsAuthenticated() {
    agent.AddTool(fileReadTool)
    agent.AddTool(fileWriteTool)
}

// Revoke on logout
agent.RemoveTool("file_read")
agent.RemoveTool("file_write")
```

## How It Works

1. **Initialization**: When you create a `ChatAgent`, it:
   - Creates an underlying agent graph using `CreateAgent`
   - Generates a unique session ID (UUID)
   - Initializes an empty message history
   - Initializes an empty dynamic tools list

2. **Message Flow**: When you call `Chat()`:
   - The user's message is appended to the conversation history
   - Dynamic tools (if any) are added to the input state as `extra_tools`
   - The full history and tools are passed to the agent graph
   - The agent processes the messages with available tools and generates a response
   - The response is added to the history
   - The text response is extracted and returned

3. **Tool Management**: The `ChatAgent` maintains two sets of tools:
   - **Base Tools**: Provided during agent creation (via `NewChatAgent`)
   - **Dynamic Tools**: Added/removed at runtime via management methods
   - Both sets are available to the agent during processing

4. **State Management**: The `ChatAgent` maintains:
   - A unique `threadID` for session identification
   - A `messages` slice containing the full conversation history
   - A `dynamicTools` slice containing runtime-added tools
   - A reference to the underlying `StateRunnable` agent

## Configuration Options

You can customize the ChatAgent using the same options as `CreateAgent`:

```go
agent, err := prebuilt.NewChatAgent(
    model,
    tools,
    prebuilt.WithSystemMessage("You are a helpful assistant."),
    prebuilt.WithVerbose(true),
)
```

Available options:
- `WithSystemMessage(message string)`: Set a system message
- `WithStateModifier(func)`: Modify messages before sending to the model
- `WithVerbose(verbose bool)`: Enable verbose logging
- `WithSkillDir(dir string)`: Enable skill-based tool selection

## Async Streaming Use Cases

The async streaming methods (`AsyncChat` and `AsyncChatWithChunks`) provide several benefits:

### 1. Better User Experience

Display responses in real-time as they're generated:

```go
respChan, _ := agent.AsyncChatWithChunks(ctx, "Explain machine learning")
for word := range respChan {
    fmt.Print(word)
    time.Sleep(50 * time.Millisecond)  // Typing effect
}
```

### 2. Perceived Performance

Users see immediate feedback instead of waiting for complete response:

```go
// User sees response starting immediately
respChan, _ := agent.AsyncChat(ctx, message)
for char := range respChan {
    updateUI(char)  // Update UI in real-time
}
```

### 3. Interruptible Responses

Cancel long responses that aren't relevant:

```go
ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
defer cancel()

respChan, _ := agent.AsyncChat(ctx, "Tell me everything about...")
// Stream will stop when timeout occurs
```

### 4. Progress Indicators

Show progress while response is being generated:

```go
go func() {
    for range time.Tick(500 * time.Millisecond) {
        fmt.Print(".")  // Show activity
    }
}()

// Meanwhile, stream the response
for word := range respChan {
    fmt.Print(word)
}
```

## Examples

- **Basic Multi-Turn Conversation**: See `examples/chat_agent/main.go` for a complete working example
- **Dynamic Tool Management**: See `examples/chat_agent_dynamic_tools/main.go` for dynamic tool usage
- **Async Streaming**: See `examples/chat_agent_async/main.go` for streaming responses

## Notes

- Each `ChatAgent` instance represents a single conversation session
- Conversation history is maintained in memory for the lifetime of the instance
- For persistent conversations across application restarts, you would need to save and restore the message history
- The underlying agent uses LangGraph's state management with `AppendReducer` for messages
